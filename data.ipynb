{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotheken importieren\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV-Datei mit Semikolon als Trennzeichen lesen\n",
    "df = pd.read_csv('data.csv', sep=';')\n",
    "df.rename(columns=lambda x: re.sub(r'\\W+', ' ', x).strip(), inplace=True)\n",
    "# Die ersten fünf Zeilen anzeigen\n",
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Überprüfen, welche Werte NaN sind (True = NaN, False = kein NaN)\n",
    "print(df.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spaltennamen bereinigen\n",
    "cleaned_columns = [\n",
    "    \"marital_status\",\n",
    "    \"application_mode\",\n",
    "    \"application_order\",\n",
    "    \"course\",\n",
    "    \"daytime_evening_attendance\",\n",
    "    \"previous_qualification\",\n",
    "    \"previous_qualification_grade\",\n",
    "    \"nationality\",          # Korrektur von \"Nacionality\"\n",
    "    \"mothers_qualification\", # Apostroph und Leerzeichen entfernt\n",
    "    \"fathers_qualification\", # Apostroph und Leerzeichen entfernt\n",
    "    \"mothers_occupation\",\n",
    "    \"fathers_occupation\",\n",
    "    \"admission_grade\",\n",
    "    \"displaced\",\n",
    "    \"educational_special_needs\",\n",
    "    \"debtor\",\n",
    "    \"tuition_fees_up_to_date\",\n",
    "    \"gender\",\n",
    "    \"scholarship_holder\",\n",
    "    \"age_at_enrollment\",\n",
    "    \"international\",\n",
    "    \"curricular_units_1st_sem_credited\",\n",
    "    \"curricular_units_1st_sem_enrolled\",\n",
    "    \"curricular_units_1st_sem_evaluations\",\n",
    "    \"curricular_units_1st_sem_approved\",\n",
    "    \"curricular_units_1st_sem_grade\",\n",
    "    \"curricular_units_1st_sem_without_evaluations\",\n",
    "    \"curricular_units_2nd_sem_credited\",\n",
    "    \"curricular_units_2nd_sem_enrolled\",\n",
    "    \"curricular_units_2nd_sem_evaluations\",\n",
    "    \"curricular_units_2nd_sem_approved\",\n",
    "    \"curricular_units_2nd_sem_grade\",\n",
    "    \"curricular_units_2nd_sem_without_evaluations\",\n",
    "    \"unemployment_rate\",\n",
    "    \"inflation_rate\",\n",
    "    \"gdp\",\n",
    "    \"target\"\n",
    "]\n",
    "\n",
    "# Spalten umbenennen\n",
    "df.columns = cleaned_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Überprüfung aller fehlenden Werte in einem Befehl\n",
    "missing_values = df.isnull() | df.eq('') | df.eq('None') | df.eq('null') | df.eq('?') | df.eq('-') | df.eq('N/A') | df.eq('unknown')\n",
    "# Anzahl der fehlenden Werte pro Spalte\n",
    "missing_values.sum()\n",
    "# Summe aller fehlenden Werte im gesamten DataFrame\n",
    "missing_values.sum().sum()\n",
    "# Zeige alle Zeilen, die mindestens einen fehlenden Wert haben\n",
    "print(df[missing_values.any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df.columns)\n",
    "#print(df.dtypes)\n",
    "print(df.dtypes.value_counts())\n",
    "print(df.dtypes.unique())\n",
    "for spalte in df.columns:\n",
    "    if df.dtypes[spalte]=='object':\n",
    "\n",
    "        print('spalte ist :', spalte)\n",
    "object_spalten = df.select_dtypes(include='object').columns\n",
    "print(object_spalten)\n",
    "print(df.loc[:,'target'])\n",
    "print(df['target'].unique())\n",
    "df['target'] = df['target'].astype('category')\n",
    "#\n",
    "dezimal_liste=[]\n",
    "for spalte in df.columns:\n",
    "    if df.dtypes[spalte]=='float64':\n",
    "        #print('spalte ist Dezimal:', spalte)\n",
    "        dezimal_liste.append(spalte)\n",
    "print(dezimal_liste)\n",
    "# Schleife, um die angegebenen Spalten in 'int64' umzuwandeln\n",
    "#umwandeln_Liste = ['Age at enrollment', 'Curricular units 1st sem grade', 'Curricular units 2nd sem credited']\n",
    "umwandeln_liste = [\n",
    "    'age_at_enrollment',                 # Vorher: 'Age at enrollment'\n",
    "    'curricular_units_1st_sem_grade',    # Vorher: 'Curricular units 1st sem grade'\n",
    "    'curricular_units_2nd_sem_credited'  # Vorher: 'Curricular units 2nd sem credited'\n",
    "]\n",
    "\n",
    "\n",
    "for spalte in umwandeln_liste:\n",
    "    if spalte in df.columns:  # Überprüfen, ob die Spalte im DataFrame existiert\n",
    "        df[spalte] = df[spalte].astype('int64')\n",
    "\n",
    "# Die Datentypen der umgewandelten Spalten anzeigen\n",
    "print(df[umwandeln_liste].dtypes)\n",
    "###################################################################################################################################################\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################################################\n",
    "#Korrelation\n",
    "# Bibliotheken importieren\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------- KORRELATIONSMATRIX VISUALISIEREN ----------------------------\n",
    "\n",
    "# 1. Nur numerische Spalten auswählen\n",
    "df_numeric = df.select_dtypes(include=['float64', 'int64']).copy()\n",
    "\n",
    "# 2. Spalten mit Standardabweichung = 0 entfernen\n",
    "df_numeric = df_numeric.loc[:, df_numeric.std(numeric_only=True) != 0]\n",
    "\n",
    "# 3. Fehlende Werte mit dem Median auffüllen \n",
    "df_numeric = df_numeric.fillna(df_numeric.median())\n",
    "\n",
    "# 4. Korrelationsmatrix berechnen\n",
    "correlation_matrix = df_numeric.corr()\n",
    "\n",
    "# 5. Heatmap visualisieren\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Korrelationsmatrix der numerischen Spalten', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "## ---------------------------- STARKE KORRELATIONEN HERAUSFILTERN ----------------------------\n",
    "\n",
    "## Schwellenwert für starke Korrelationen festlegen\n",
    "#threshold = 0.8\n",
    "\n",
    "## 1. Starke Korrelationen finden (ohne Diagonale)\n",
    "#starke_korrelationen = [\n",
    "    #(spalte1, spalte2, correlation_matrix.loc[spalte1, spalte2])\n",
    "    #for spalte1 in correlation_matrix.columns\n",
    "    #for spalte2 in correlation_matrix.columns\n",
    "    #if spalte1 != spalte2 and abs(correlation_matrix.loc[spalte1, spalte2]) >= threshold\n",
    "#]\n",
    "\n",
    "## 2. Starke Korrelationen ausgeben (vereinfacht)\n",
    "#print(\"\\nStarke Korrelationen:\" if starke_korrelationen else \"\\nKeine gefunden.\")\n",
    "#for spalte1, spalte2, corr in starke_korrelationen:\n",
    "    #print(spalte1, spalte2, round(corr, 2))\n",
    "\n",
    "## 3. Stark korrelierte Spalten löschen (jeweils die zweite aus jedem Paar)\n",
    "#columns_to_drop = []\n",
    "#for spalte1, spalte2, corr in starke_korrelationen:\n",
    "    #if spalte2 not in columns_to_drop:\n",
    "        #columns_to_drop.append(spalte2)  # Zweite Spalte wird gelöscht\n",
    "\n",
    "## 4. Stark korrelierte Spalten entfernen\n",
    "#df_numeric.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "## 5. Gelöschte Spalten anzeigen\n",
    "#if columns_to_drop:\n",
    "    #print(\"\\nGelöschte Spalten:\")\n",
    "    #print(*sorted(columns_to_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#######################################Zielvariable 'Target' analysieren###########################################\n",
    "print(df.columns)\n",
    "print(df['target'].isna().sum())\n",
    "print(df['target'].unique())\n",
    "#\n",
    "# Prozentuale Verteilung anzeigen\n",
    "print(\"\\nVerteilung der Zielvariable 'target':\")\n",
    "print(df['target'].value_counts(normalize=True))  \n",
    "\n",
    "# Histogramm plotten\n",
    "plt.hist(df['target'].dropna(), bins=[-0.5, 0.5, 1.5, 2.5], rwidth=0.8, \n",
    "         color='skyblue', edgecolor='black')  \n",
    "plt.title(\"Verteilung der Zielvariable 'target'\")\n",
    "plt.xlabel(\"target (0 = Dropout, 1 = Enrolled, 2 = Graduate)\")\n",
    "plt.ylabel(\"Anzahl\")\n",
    "plt.xticks([0, 1, 2], labels=[\"Dropout (0)\", \"Enrolled (1)\", \"Graduate (2)\"])\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)  \n",
    "plt.show()\n",
    "###############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zielvariable „Dropout“ in Binärspalte umwandeln\n",
    "df['dropout'] = df['target'].apply(lambda x: 1 if x == 'Dropout' else 0)\n",
    "df['dropout'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auskommentiert, da strings in LogRegression nicht akzeptiert werden\n",
    "# Sonstige Berufe sind auffällig\n",
    "# Berufe der Eltern gruppieren - Bei Bedarf gerne überprüfen und anpassen\n",
    "# def group_occupation(code):\n",
    "#     if code in [1, 2, 112, 114, 121, 122, 123, 124, 125, 101, 102, 103]:  \n",
    "#         return \"Hochqualifiziert\" # Führungskräfte, Akademiker etc\n",
    "#     elif code in [3, 4, 131, 132, 134, 135, 141, 143, 144, 125, 135]:\n",
    "#         return \"Mittelqualifiziert\" # Technisch, Verwaltung, Gesundheitsberufe, Büro\n",
    "#     elif code in [5, 6, 7, 8, 152, 153, 154, 161, 163, 171, 172, 173, 174, 175, 181, 182, 183, 192, 193, 194, 195]:\n",
    "#         return \"Handwerk & manuelle Berufe\" # Verkauf, Bau, Handwerk, Landwirtschaft, etc. \n",
    "#     elif code in [9, 191, 192, 193, 194, 195]:\n",
    "#         return \"Einfache Tätigkeiten\" # Ungelernte Arbeiter, Hilfskräfte, etc.\n",
    "#     elif code in [0, 10, 90, 99, 101, 102, 103]: # Sonstige\n",
    "#         return \"Sonstige\"\n",
    "#     else:\n",
    "#         return \"Sonstige\"\n",
    "\n",
    "# # Neue Spalten mit gruppierten Berufen:\n",
    "# df['father_occ_group'] = df[\"fathers_occupation\"].apply(group_occupation)\n",
    "# df['mother_occ_group'] = df[\"mothers_occupation\"].apply(group_occupation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NICHT AUSFÜHREN!\n",
    "# 1) Dropout-Rate nach Berufsgruppe des Vaters\n",
    "# plt.figure(figsize=(8,4))\n",
    "# sns.barplot(\n",
    "#     data=df, \n",
    "#     x='father_occ_group', \n",
    "#     y='dropout', \n",
    "#     estimator=lambda x: sum(x)/len(x),  # Anteil Dropout (durchschnitt der Binärvariable)\n",
    "#     errorbar='se',                     # Standardfehler als Fehlerbalken\n",
    "#     order=['Hochqualifiziert','Mittelqualifiziert',\n",
    "#            'Handwerk & manuelle Berufe','Einfache Tätigkeiten','Sonstige']\n",
    "# )\n",
    "# plt.ylim(0, 1)\n",
    "# plt.xlabel('Berufsgruppe Vater')\n",
    "# plt.ylabel('Dropout-Rate')\n",
    "# plt.title('Dropout-Rate nach Berufsgruppe des Vaters')\n",
    "# plt.xticks(rotation=25, ha='right')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # 2) Dropout-Rate nach Berufsgruppe der Mutter\n",
    "# plt.figure(figsize=(8,4))\n",
    "# sns.barplot(\n",
    "#     data=df, \n",
    "#     x='mother_occ_group', \n",
    "#     y='dropout', \n",
    "#     estimator=lambda x: sum(x)/len(x),\n",
    "#     errorbar='se',\n",
    "#     order=['Hochqualifiziert','Mittelqualifiziert',\n",
    "#            'Handwerk & manuelle Berufe','Einfache Tätigkeiten','Sonstige']\n",
    "# )\n",
    "# plt.ylim(0, 1)\n",
    "# plt.xlabel('Berufsgruppe Mutter')\n",
    "# plt.ylabel('Dropout-Rate')\n",
    "# plt.title('Dropout-Rate nach Berufsgruppe der Mutter')\n",
    "# plt.xticks(rotation=25, ha='right')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Auskommentiert, da strings in LogRegression nicht akzeptiert werden\n",
    "# Sonstige Qualifikationen sind auffällig\n",
    "# Bildungsniveau der Eltern gruppieren\n",
    "# education_groups = {\n",
    "#     \"Grundbildung\": [9, 10, 11, 12, 14, 15, 19, 26, 27, 29, 30, 37, 38],\n",
    "#     \"Mittlere Bildung\": [1, 18, 22, 39, 42],\n",
    "#     \"Hochschulabschluss\": [2, 3, 4, 5, 40, 43, 44],\n",
    "#     \"Unbekannt\": [34, 35, 36]\n",
    "# }\n",
    "\n",
    "# def map_education(code):\n",
    "#     for group, codes in education_groups.items():\n",
    "#         if code in codes:\n",
    "#             return group\n",
    "#     return \"Unbekannt\"\n",
    "\n",
    "# df[\"mothers_qualification_group\"] = df[\"mothers_qualification\"].apply(map_education)\n",
    "# df[\"fathers_qualification_group\"] = df[\"fathers_qualification\"].apply(map_education)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Dropout-Rate nach Bildungsniveau des Vaters\n",
    "# plt.figure(figsize=(8,4))\n",
    "# sns.barplot(\n",
    "#     data=df,\n",
    "#     x='fathers_qualification_group', \n",
    "#     y='dropout',\n",
    "#     estimator=lambda x: sum(x)/len(x),\n",
    "#     errorbar='se',\n",
    "#     order=[\"Hochschulabschluss\", \"Mittlere Bildung\", \"Grundbildung\", \"Unbekannt\"]\n",
    "# )\n",
    "# plt.ylim(0, 1)\n",
    "# plt.xlabel('Bildungsniveau Vater')\n",
    "# plt.ylabel('Dropout-Rate')\n",
    "# plt.title('Dropout-Rate nach Bildungsniveau des Vaters')\n",
    "# plt.xticks(rotation=25, ha='right')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # 2) Dropout-Rate nach Bildungsniveau der Mutter\n",
    "# plt.figure(figsize=(8,4))\n",
    "# sns.barplot(\n",
    "#     data=df,\n",
    "#     x='mothers_qualification_group', \n",
    "#     y='dropout',\n",
    "#     estimator=lambda x: sum(x)/len(x),\n",
    "#     errorbar='se',\n",
    "#     order=[\"Hochschulabschluss\", \"Mittlere Bildung\", \"Grundbildung\", \"Unbekannt\"]\n",
    "# )\n",
    "# plt.ylim(0, 1)\n",
    "# plt.xlabel('Bildungsniveau Mutter')\n",
    "# plt.ylabel('Dropout-Rate')\n",
    "# plt.title('Dropout-Rate nach Bildungsniveau der Mutter')\n",
    "# plt.xticks(rotation=25, ha='right')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idee ist eine Schleife zu schaffen, die durch alle Variablen in Abhängigkeit von der Zielvariable als Balkendiagramme darstellt. Für alle Variablen eine absolute und eine relative Verteilung.\n",
    "# Insgesamt möchte ich demnach 36-mal 2 Balkendiagramme erstellen\n",
    "\n",
    "\n",
    "# CSV-Datei mit Semikolon als Trennzeichen einlesen\n",
    "df = pd.read_csv('data.csv', sep=';')\n",
    "\n",
    "# Spaltennamen bereinigen\n",
    "df.rename(columns=lambda x: re.sub(r'\\W+', ' ', x).strip(), inplace=True)\n",
    "\n",
    "# Liste aller Features außer der Zielvariable \"Target\"\n",
    "features = df.columns.tolist()\n",
    "features.remove(\"Target\")  # Falls \"Target\" deine Zielvariable ist\n",
    "\n",
    "# Erstellen der Plots für jedes Feature\n",
    "for feature in features:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "\n",
    "    # 1) Relative Verteilung (Dropout-Rate)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.barplot(\n",
    "        data=df,\n",
    "        x=feature,\n",
    "        y=df[\"Target\"].apply(lambda x: 1 if x == \"Dropout\" else 0),  # Binäre Dropout-Rate\n",
    "        estimator=lambda x: sum(x) / len(x),  # Durchschnitt = Anteil Dropout\n",
    "        errorbar=\"se\"\n",
    "    )\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Dropout-Rate\")\n",
    "    plt.title(f\"Dropout-Rate nach {feature}\")\n",
    "    plt.xticks(rotation=25, ha=\"right\")\n",
    "\n",
    "    # 2) Absolute Verteilung\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.countplot(data=df, x=feature, hue=\"Target\")\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Anzahl\")\n",
    "    plt.title(f\"Absolute Verteilung nach {feature}\")\n",
    "    plt.xticks(rotation=25, ha=\"right\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Ergebnisse: Z.T. sind noch Gruppierungen oder andere Darstellungsformen notwendig\n",
    "# Ziel der Detailanalyse: Finden von Untergruppen (z.B. Marital Status = 6 (legally separated)) sollten individuell wirksamer gefördert werden. Der Anteil an Dropouts ist signifikant höher als bei den  anderen Gruppen. EBenfalls interessant wäre eine Förderung der Gruppe 1. Diese ist zwar relativ die zweitbbeste, aber absolut mit Abstand die größte gruppe\n",
    "\n",
    "# Analyse Marital Status\n",
    "# Gezielte Förderung für Statusgruppe 1 (single) und andere gefährdete Gruppen:\n",
    "# Implementierung von Mentoring-Programmen, um persönliche und akademische Unterstützung anzubieten.\n",
    "# Finanzielle Entlastung durch Stipendien oder subventionierte Ressourcen, die speziell auf bedürftige Gruppen abzielen.\n",
    "# Individuelle Betreuung und psychologische Unterstützung:\n",
    "# Aufbau eines leicht zugänglichen Netzwerks von Beratern, die auf die jeweiligen Bedürfnisse der Statusgruppen eingehen können.\n",
    "# Stärkung der Gemeinschaft:\n",
    "# Förderung von sozialen Aktivitäten und Netzwerken, die die Bindung zur Hochschule erhöhen und Isolation vorbeugen.\n",
    "# Monitoring und Evaluation:\n",
    "# Einführung eines fortlaufenden Monitoring-Systems, um die Wirksamkeit der Maßnahmen zu bewerten und gegebenenfalls anzupassen.\n",
    "\n",
    "# Analyse Application Mode\n",
    "# 1. Überblick der Daten:\n",
    "# Relative Dropout-Rate: Die linke Grafik zeigt für jeden Bewerbungsmodus den Anteil der Studierenden, die ihr Studium abbrechen, relativ zu den Gesamtzahlen dieser Gruppe. Die Werte reichen von nahezu 0% bis etwa 60%, wobei Fehlerbalken die Streuung oder Unsicherheit der Daten anzeigen.\n",
    "# Absolute Verteilung: Die rechte Grafik zeigt die Gesamtanzahl der Studierenden pro Bewerbungsmodus, unterteilt in die Kategorien \"Dropout\", \"Graduate\" und \"Enrolled\". Dies bietet einen Überblick über die zahlenmäßige Gewichtung der einzelnen Gruppen.\n",
    "# 2. Kernaussagen der Analyse:\n",
    "# Die höchsten Dropout-Raten liegen bei den Modi 5, 15, und 16, mit Werten von etwa 50–60%. Dies deutet darauf hin, dass Studierende, die sich über diese speziellen Kontingente (wie Azoren- oder Madeira-Inseln sowie internationale Studierende im Bachelor) einschreiben, besonders anfällig für Studienabbrüche sind.\n",
    "# Besonders alarmierend ist dabei, dass Modus 15 (Internationale Studierende) die höchste Dropout-Rate aufweist. Dies könnte auf sprachliche Barrieren, kulturelle Anpassungsschwierigkeiten oder finanzielle Herausforderungen hindeuten.\n",
    "# Modi 3 und 7 haben die niedrigsten Dropout-Raten von etwa 10%. Diese Modus-Gruppen scheinen stabiler zu sein, möglicherweise aufgrund von vorherigen akademischen Abschlüssen oder besserer Vorbereitung auf das Studium.\n",
    "# Quantitativer Einfluss:\n",
    "# Die rechte Grafik zeigt, dass Modi wie 1 (General Contingent) und 17/18 (2. und 3. Phase des General Contingent) in absoluten Zahlen die größte Anzahl an Studierenden umfassen. Auch wenn ihre relativen Dropout-Raten niedriger sind (ca. 20–30%), ist die absolute Anzahl der Studienabbrüche in diesen Gruppen aufgrund ihrer Größe signifikant.\n",
    "# 3. Handlungsempfehlungen:\n",
    "# Auf Basis dieser Analyse lassen sich drei Kernstrategien ableiten, um die Studienabbrüche gezielt zu reduzieren:\n",
    "# 1. Unterstützung für Hochrisiko-Gruppen (z.B. Modi 5, 15, 16):\n",
    "# Sprachliche und kulturelle Integration: Internationale Studierende könnten durch verstärkte Sprachkurse und kulturelle Orientierungsprogramme besser auf die Herausforderungen vorbereitet werden.\n",
    "# Finanzielle Unterstützung: Für Studierende aus den Azoren und Madeira-Inseln könnten zusätzliche finanzielle Hilfen bereitgestellt werden, um die Kosten für Reisen und Lebenshaltung zu reduzieren.\n",
    "# Mentoring-Programme: Ein Tandem-Programm, das erfahrene Studierende mit Neueinsteigern verbindet, könnte den sozialen und akademischen Einstieg erleichtern.\n",
    "# 2. Fokus auf allgemeine Contingent-Gruppen (z.B. Modi 1, 17, 18):\n",
    "# Frühzeitiges Monitoring: Gerade in diesen großen Gruppen könnten Frühwarnsysteme eingeführt werden, die gefährdete Studierende identifizieren, bevor sie abbrechen.\n",
    "# Zugeschnittene Beratung: Regelmäßige Beratungsgespräche zu Themen wie Studienorganisation, Stressmanagement und Karriereplanung könnten helfen, Unsicherheiten frühzeitig zu adressieren.\n",
    "# 3. Förderung der Erfolgsfaktoren der stabilen Gruppen (z.B. Modi 3, 7):\n",
    "# Transfer von Best Practices: Die Erfolgsfaktoren dieser Gruppen, wie z.B. vorherige akademische Erfahrungen oder spezielle Vorbereitungskurse, sollten analysiert und auf andere Gruppen angewendet werden.\n",
    "# Ausbau der Unterstützungsstruktur: Stabile Gruppen können als Mentoren oder Peer-Tutoren fungieren, um ihr Wissen und ihre Erfahrungen weiterzugeben.\n",
    "# 4. Fazit:\n",
    "# Die Datenanalyse zeigt, dass es sowohl Gruppen mit hohen Dropout-Raten als auch große Gruppen mit niedrigeren, aber dennoch signifikanten absoluten Abbruchzahlen gibt. Besonders herausfordernd sind die Modi 5, 15 und 16, während Gruppen wie Modus 3 und 7 als Vorbilder dienen können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel: Scholarship vs. Dropout\n",
    "# Dropout ohne Stidiendium höher\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(\n",
    "    data=df, \n",
    "    x='scholarship_holder',      # 0 = kein Stipendium, 1 = Stipendium\n",
    "    y='dropout',\n",
    "    estimator=lambda x: sum(x)/len(x)  # Anteil (üblicherweise ist das default => mean)\n",
    ")\n",
    "plt.title('Anteil der Dropouts je Stipendiumsstatus')\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel('Dropout-Rate')\n",
    "plt.xlabel('Scholarship holder (0=nein, 1=ja)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hohe Arbeitslosenrate korreliert mit niedrigem Dropout\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(x='unemployment_rate',data=df,hue='target',multiple='stack')\n",
    "\n",
    "plt.title(\"Verteilung der Arbeitslosenrate nach Studienerfolg\", fontsize=14, pad=20)\n",
    "plt.xlabel(\"Arbeitslosenrate (in %)\", fontsize=12)\n",
    "plt.ylabel(\"Anzahl der Studierenden\", fontsize=12)\n",
    "plt.legend(title=\"Studienstatus\",labels=[\"Absolvent\", \"Eingeschrieben\", \"Dropout\"], )\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.histplot(\n",
    "    data=df, \n",
    "    x='unemployment_rate', \n",
    "    hue='target',\n",
    "    multiple='fill',    \n",
    "    stat='probability'   \n",
    ")\n",
    "\n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1.0))  # skaliert 0..1 in 0..100%\n",
    "plt.title(\"Verteilung der Arbeitslosenrate nach Studienerfolg (relativ)\", fontsize=14, pad=20)\n",
    "plt.xlabel(\"Arbeitslosenrate (in %)\", fontsize=12)\n",
    "plt.ylabel(\"Prozentanteil pro Bin\", fontsize=12)\n",
    "plt.legend(title=\"Studienstatus\", labels=[\"Absolvent\", \"Eingeschrieben\", \"Dropout\"])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Zielvariable und Features definieren\n",
    "X = df.drop(columns=['target'])\n",
    "y = df.loc[:,'target']\n",
    "\n",
    "# Daten in Trainings- und Testdatensätze aufteilen\n",
    "# Kemal: Test von 0.1 auf 0.2 geändert\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "###########################################################################################################\n",
    "\n",
    "# 4. Testdaten speichern\n",
    "features_test = pd.concat([X_test, y_test], axis=1)  # Test-Features mit Zielvariable zusammenfügen\n",
    "features_test.to_csv('features_test.csv', index=False)  # CSV-Datei speichern\n",
    "#\n",
    "print(\"Testdaten wurden erfolgreich als 'features_test.csv' gespeichert.\")\n",
    "###########################################################################################################\n",
    "\n",
    "\n",
    "# Numerische und Kategorische Spalten identifizieren\n",
    "numeric_columns = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_columns = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "print(\"Numerische Spalten:\", numeric_columns)\n",
    "print(\"Kategorische Spalten:\", categorical_columns)\n",
    "#################################################################################################\n",
    "# Kopien von X_train und X_test erstellen, um Slices zu vermeiden\n",
    "X_train = X_train.copy()\n",
    "X_test = X_test.copy()\n",
    "#################################################################################################\n",
    "# Kategorische Spalten in 'category' umwandeln\n",
    "for col in categorical_columns:\n",
    "    X_train[col] = X_train[col].astype('category')\n",
    "    X_test[col] = X_test[col].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median für numerische Spalten berechnen\n",
    "numeric_columns = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "median_train = dict(X_train[numeric_columns].median())\n",
    "\n",
    "#print(\"Median für numerische Spalten:\", median_train)\n",
    "#################################################################################################################\n",
    "# 2. Modus für kategorische Spalten berechnen und anpassen\n",
    "categorical_columns = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "mode = X_train[categorical_columns].mode().to_dict()\n",
    "\n",
    "# Modus-Dictionary anpassen\n",
    "mode_train = {}\n",
    "for category, inner_dict in mode.items():\n",
    "    for key, value in inner_dict.items():\n",
    "        mode_train[category] = value\n",
    "\n",
    "#print(\"Modus für kategorische Spalten:\", mode_train)\n",
    "###################################################################################################################\n",
    "# 3. Fehlende Werte ersetzen (Numerisch: Median, Kategorisch: Modus)\n",
    "for col in numeric_columns:\n",
    "    X_train[col] = X_train[col].fillna(median_train[col])\n",
    "    X_test[col] = X_test[col].fillna(median_train[col])\n",
    "\n",
    "for col in categorical_columns:\n",
    "    X_train[col] = X_train[col].fillna(mode_train[col])\n",
    "    X_test[col] = X_test[col].fillna(mode_train[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######Deal with Outliers############################################################################################################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels import robust\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "np.log1p(df.select_dtypes(include=['float64', 'int64'])).boxplot(rot=90)  # log1p = log(x+1) vermeidet log(0)\n",
    "plt.title('Boxplots der numerischen Spalten (Log-Transformation)', fontsize=16)\n",
    "plt.show()\n",
    "#\n",
    "#Ausreißer\n",
    "\n",
    "\n",
    "def handle_outliers(data, numeric_columns, threshold=15):\n",
    "    \"\"\"\n",
    "    Behandelt Ausreißer in den numerischen Spalten eines DataFrames.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Der zu verarbeitende DataFrame.\n",
    "        numeric_columns (list): Liste der numerischen Spalten.\n",
    "        threshold (int): Schwellenwert für die MAD (Median Absolute Deviation).\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Der DataFrame mit behandelten Ausreißern.\n",
    "    \"\"\"\n",
    "    outlier_indices = set()  # Speichert die Indizes der Ausreißer\n",
    "    print(\"\\n--- Ausreißeranalyse ---\")\n",
    "    \n",
    "    for col in numeric_columns:\n",
    "        median = data[col].median()\n",
    "        mad = robust.mad(data[col])\n",
    "        \n",
    "        if mad == 0:  # Wenn MAD 0 ist, überspringen\n",
    "            print(f\"MAD ist für Spalte {col} 0. Ausreißeranalyse wird übersprungen.\")\n",
    "            continue\n",
    "        \n",
    "        lower_bound = median - threshold * mad\n",
    "        upper_bound = median + threshold * mad\n",
    "        \n",
    "        # Ausreißer identifizieren\n",
    "        col_outliers = data[(data[col] < lower_bound) | (data[col] > upper_bound)]\n",
    "        print(f\"Spalte {col}: {len(col_outliers)} Ausreißer gefunden.\")\n",
    "        \n",
    "        # Ausreißer durch Median ersetzen\n",
    "        data.loc[col_outliers.index, col] = median\n",
    "        outlier_indices.update(col_outliers.index)\n",
    "    \n",
    "    # Statistik über Ausreißer\n",
    "    total_outliers = len(outlier_indices)\n",
    "    percentage_outliers = (total_outliers / len(data)) * 100\n",
    "    print(f\"\\nGesamtanzahl der eindeutigen Ausreißer: {total_outliers}\")\n",
    "    print(f\"Prozentsatz der Ausreißer: {percentage_outliers:.2f}%\")\n",
    "    \n",
    "    return data\n",
    "#\n",
    "# Numerische Spalten identifizieren\n",
    "numeric_columns = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Ausreißer in X_train behandeln\n",
    "X_train = handle_outliers(X_train, numeric_columns)\n",
    "print(\"Ausreißer in X_train wurden behandelt.\")\n",
    "#\n",
    "plt.figure(figsize=(12, 8))\n",
    "np.log1p(df.select_dtypes(include=['float64', 'int64'])).boxplot(rot=90)\n",
    "plt.title('Boxplots nach der Ausreißerbehandlung', fontsize=16)\n",
    "plt.show()\n",
    "###############################################################################################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop('dropout', axis=1)\n",
    "X_test = X_test.drop('dropout', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score, f1_score, recall_score, precision_score\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "logreg.fit(X_train, y_train)\n",
    "predictions = logreg.predict(X_test)\n",
    "print(\"Accuracy: \", accuracy_score(y_test,predictions))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test,predictions))\n",
    "print(\"\\n\")\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_f = RandomForestClassifier(n_estimators=100)\n",
    "random_f.fit(X_train, y_train)\n",
    "predictions = random_f.predict(X_test)\n",
    "print(\"Accuracy: \", accuracy_score(y_test,predictions))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test,predictions))\n",
    "print(\"\\n\")\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Pipeline\n",
    "rf_pipeline = Pipeline([\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5],\n",
    "    'classifier__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',         \n",
    "    verbose=1, \n",
    "    cv=5,                \n",
    "    n_jobs=-1             \n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "print(\"Bestes CV-Ergebnis (mean test score):\", grid_search.best_score_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "best_params = {\n",
    "    'class_weight': 'balanced',\n",
    "    'max_depth': 20,\n",
    "    'min_samples_split': 2,\n",
    "    'n_estimators': 200\n",
    "}\n",
    "\n",
    "random_f = RandomForestClassifier(\n",
    "    class_weight=best_params['class_weight'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "random_f.fit(X_train, y_train)\n",
    "predictions = random_f.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, predictions))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = random_f.feature_importances_\n",
    "feature_names = X_train.columns  \n",
    "\n",
    "\n",
    "feat_importances = pd.Series(importances, index=feature_names)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "feat_importances.nlargest(20).plot(kind='barh')\n",
    "plt.title(\"Top 20 Feature Importances (Random Forest)\")\n",
    "plt.xlabel(\"Feature Importance Score\")\n",
    "plt.ylabel(\"Feature Name\")\n",
    "plt.gca().invert_yaxis()  \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(\n",
    "    data=df_no_outlier, \n",
    "    x='curricular_units_2nd_sem_approved', \n",
    "    y='curricular_units_2nd_sem_grade', \n",
    "    #size='curricular_units_2nd_sem_approved',\n",
    "    #sizes=(20, 200),\n",
    "    hue='target',        \n",
    "    alpha=0.7              \n",
    ")\n",
    "plt.title(\"Studentenstatus nach bestandenen Kursen udn Noten\")\n",
    "plt.xlabel(\"Im 2. Semester bestandene Kurse/Module\")\n",
    "plt.ylabel(\"Note im 2. Semester\")\n",
    "plt.legend(title=\"Klasse\") \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Grafik zeigt, dass Studierende mit vielen bestandenen Kursen im zweiten Semester häufig auch höhere Durchschnittsnoten erzielen. Im Gegensatz dazu konzentrieren sich viele Dropout-Fälle dort, wo nur wenige Lehrplaneinheiten erfolgreich absolviert wurden und/oder die Noten eher niedrig ausfallen. Studierende, die noch eingeschrieben sind („Enrolled“), liegen meist zwischen diesen beiden Extremen und weisen mittelmäßige Werte bei sowohl bestandenen Kursen als auch Noten auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropout = df_no_outlier[df[\"target\"] == \"Dropout\"]\n",
    "df_other   = df_no_outlier[df[\"target\"] != \"Dropout\"]\n",
    "\n",
    "sns.scatterplot(data=df_other, x=\"curricular_units_2nd_sem_approved\", y=\"curricular_units_2nd_sem_grade\", alpha=0.3, color=\"gray\", s=50)\n",
    "sns.scatterplot(data=df_dropout, x=\"curricular_units_2nd_sem_approved\", y=\"curricular_units_2nd_sem_grade\", color=\"blue\", s=50, label=\"Dropout\")\n",
    "\n",
    "plt.title(\"Dropout nach bestandenen Kursen und Noten\")\n",
    "plt.xlabel(\"Im 2. Semester bestandene Kurse/Module\")\n",
    "plt.ylabel(\"Note im 2. Semester\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data=df_no_outlier,\n",
    "    x='curricular_units_2nd_sem_grade',   \n",
    "    y='curricular_units_2nd_sem_approved',\n",
    "    col='target',                        \n",
    "    hue='target',                       \n",
    "    kind='scatter',\n",
    "    alpha=0.7,                            \n",
    "    s=40,                                 \n",
    "    height=5,                            \n",
    "    aspect=0.5,\n",
    "    legend=None                             \n",
    ")\n",
    "g.set_axis_labels(\"Note im 2. Semester\", \"Im 2. Semester bestandene Kurse/Module\")\n",
    "g.fig.suptitle(\"Bestandene Kurse nach Note und Studentenstatus\", y=1.03, fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "#  Klassen-Mapping\n",
    "class_mapping = {i: label for i, label in enumerate(label_encoder.classes_)}\n",
    "print(\"Klassen-Mapping:\", class_mapping)\n",
    "\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=200,           \n",
    "    max_depth=6,                \n",
    "    learning_rate=0.1,          \n",
    "    subsample=0.8,              \n",
    "    colsample_bytree=0.8,        \n",
    "    objective='multi:softprob',  \n",
    "    num_class=len(label_encoder.classes_),  \n",
    "    random_state=42,          \n",
    "    eval_metric='mlogloss'      \n",
    ")\n",
    "\n",
    "\n",
    "xgb_model.fit(X_train, y_train_encoded)\n",
    "xgb_predictions_encoded = xgb_model.predict(X_test)\n",
    "xgb_predictions = label_encoder.inverse_transform(xgb_predictions_encoded)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, xgb_predictions))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, xgb_predictions))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, xgb_predictions))\n",
    "\n",
    "# Feature-Importance visualisieren\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sorted_idx = np.argsort(xgb_model.feature_importances_)\n",
    "plt.barh(range(len(sorted_idx)), xgb_model.feature_importances_[sorted_idx])\n",
    "plt.yticks(range(len(sorted_idx)), np.array(X_train.columns)[sorted_idx])\n",
    "plt.title('XGBoost Feature Importance')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# Zielfunktion für Optuna\n",
    "def objective(trial):\n",
    "    # Parameter \n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': len(label_encoder.classes_),\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # Modell mit den aktuellen Parametern erstellen\n",
    "    model = XGBClassifier(**param)\n",
    "    \n",
    "    # Kreuzvalidierung \n",
    "    cv_scores = cross_val_score(model, X_train, y_train_encoded, cv=5, scoring='f1_macro')\n",
    "    \n",
    "    # Durchschnittliche Genauigkeit zurückgeben\n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "# Optuna-Studie \n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)  # Anzahl der Versuche \n",
    "\n",
    "# Beste Parameter a\n",
    "print(\"Beste Parameter:\", study.best_params)\n",
    "print(\"Beste kreuzvalidierte Genauigkeit:\", study.best_value)\n",
    "\n",
    "# Optimales Modell mit den besten Parametern erstellen\n",
    "best_params = study.best_params\n",
    "best_params['objective'] = 'multi:softprob'\n",
    "best_params['num_class'] = len(label_encoder.classes_)\n",
    "best_params['eval_metric'] = 'mlogloss'\n",
    "best_params['random_state'] = 42\n",
    "\n",
    "best_model = XGBClassifier(**best_params)\n",
    "best_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Modell auf Testdaten auswerten\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "test_predictions_encoded = best_model.predict(X_test)\n",
    "test_predictions = label_encoder.inverse_transform(test_predictions_encoded)\n",
    "\n",
    "# Endergebnisse ausgeben\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"Genauigkeit auf Testdaten:\", accuracy_score(y_test, test_predictions))\n",
    "print(\"\\nKlassifikationsbericht:\\n\", classification_report(y_test, test_predictions))\n",
    "print(\"Konfusionsmatrix:\\n\", confusion_matrix(y_test, test_predictions))\n",
    "\n",
    "f1_macro_score = f1_score(y_test, predictions, average='macro')\n",
    "print(\"F1-Makro:\", f1_macro_score)\n",
    "\n",
    "# Visualisierung der Optimierungsergebnisse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optimierungsverlauf\n",
    "plt.figure(figsize=(10, 6))\n",
    "optuna.visualization.matplotlib.plot_optimization_history(study)\n",
    "plt.title('Optimierungsverlauf')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature-Wichtigkeit des finalen Modells\n",
    "plt.figure(figsize=(10, 6))\n",
    "sorted_idx = np.argsort(best_model.feature_importances_)\n",
    "plt.barh(range(len(sorted_idx)), best_model.feature_importances_[sorted_idx])\n",
    "plt.yticks(range(len(sorted_idx)), np.array(X_train.columns)[sorted_idx])\n",
    "plt.title('XGBoost Feature-Importance (optimierte Parameter)')\n",
    "plt.xlabel('Wichtigkeit')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_viz = X_test.copy()\n",
    "df_viz['student_status'] = y_test\n",
    "\n",
    "# Mapping der Spaltennamen \n",
    "feature_names_map = {\n",
    "    'curricular_units_2nd_sem_approved': \"Bestandene Kurse im 2. Semester\",\n",
    "    'tuition_fees_up_to_date': \"Zahlung der Studiengebühren (0/1)\",\n",
    "    'curricular_units_1st_sem_approved': \"Bestandene Kurse im 1. Semester\"\n",
    "}\n",
    "\n",
    "top_features = list(feature_names_map.keys())\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1. KDE-Plots (Verteilungen) nach Studentenstatus\n",
    "# ---------------------------------------------------\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "for i, feature in enumerate(top_features, 1):\n",
    "    plt.subplot(len(top_features), 1, i)\n",
    "    \n",
    "    # Den sprechenden Namen ermitteln\n",
    "    display_name = feature_names_map[feature]\n",
    "    \n",
    "    for status in ['Dropout', 'Graduate']:\n",
    "        subset = df_viz[df_viz['student_status'] == status]\n",
    "        sns.kdeplot(data=subset, x=feature, fill=True, common_norm=False, alpha=0.6, label=status)\n",
    "    \n",
    "    plt.title(f\"Verteilung: {display_name} (Dropout vs. Graduate)\")\n",
    "\n",
    "plt.suptitle(\"Verteilungen relevanter Features zwischen Studienabbrechern und Absolventen\", \n",
    "             fontsize=16, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('feature_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2. Boxplots (Feature-Vergleich Dropout vs. Graduate)\n",
    "# ---------------------------------------------------\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "for i, feature in enumerate(top_features):\n",
    "    plt.subplot(3, 2, i+1)\n",
    "    \n",
    "    display_name = feature_names_map[feature]\n",
    "    \n",
    "    sns.boxplot(\n",
    "        x='student_status', \n",
    "        y=feature, \n",
    "        data=df_viz[df_viz['student_status'].isin(['Dropout', 'Graduate'])]\n",
    "    )\n",
    "    plt.title(f\"{display_name} nach Studentenstatus\")\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "# Leere Subplots\n",
    "if len(top_features) < 6:\n",
    "    for j in range(i+2, 7):\n",
    "        plt.subplot(3, 2, j)\n",
    "        plt.axis('off')\n",
    "\n",
    "plt.suptitle(\"Boxplot-Vergleich: Dropout vs. Graduate (Ausgewählte Features)\", fontsize=16, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.savefig('boxplot_top_features.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. KDE-Plot:\n",
    "Dropouts haben weniger bestandene Kurse.\n",
    "Graduierte verteilen sich eher in Richtung 5-15 bestandene Kurse\n",
    "Dropouts tendieren dazu, Studiengebühre nicht zu zahlen. Graduierte sind nahezu alle bei 1. Rechtzeitige Bezahlung der Studiengebühren eng mit Studienerfolg korreliert.\n",
    "Dropouts haben tendenziell weniger belegte Kurse im 1. Semester. Graduates oft mehr \n",
    "Anzahl der durchgeführten Prüfungen/Bewertungen im 1. Semester liegt bei Graduates im Mittel höher als bei Dropouts.\n",
    "Absolventen bestehen schon im 1. Semester meist deutlich mehr Kurse als Abbrecher.\n",
    "\n",
    "Bereits im ersten Semester zeichnet sich oft ein Muster ab: Wer wenig Kurse besteht und ggf. Gebühren nicht zahlt, hat ein höheres Abbruchrisiko. Im zweiten Semester verfestigt sich dieser Trend.\n",
    "\n",
    "2. Pairplot der Top‐Features\n",
    "Die selben Features im Scatterplot:\n",
    "Die blauen Punkte (Graduates) häufen sich in den Regionen mit höheren Werten.\n",
    "Ein erfolgreicher Start ins Studium scheint stark mit einem Abschluss zu korrelieren    \n",
    "\n",
    "3. Korrelationsmatrizen\n",
    "Hier werden Dropouts und Graduates seperat betrachtet. Ähnliche BEobachtungen.\n",
    "\n",
    "4. Boxplots\n",
    "Graduates haben tendenziell höhere Mediane, mit teils größerer Streuung nach oben .\n",
    "\n",
    "Fazit:\n",
    "- Frühe Semester sind entscheident: Anzahl bestandener Kurse im ersten Semester\n",
    "- Gebührenstatus als Warnsignal\n",
    "- Hochschulen könnten frühzeitig Studierende identifizieren, die im 1. Semester deutlich weniger Kurse bestehen oder mit den Gebühren in Verzug sind,  um gezielte Unterstützung anzubieten. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
